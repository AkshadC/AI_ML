{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  Strength  \n0            1040.0           676.0   28     79.99  \n1            1055.0           676.0   28     61.89  \n2             932.0           594.0  270     40.27  \n3             932.0           594.0  365     41.05  \n4             978.4           825.5  360     44.30  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n      <th>Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"concrete_data.csv\")\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "Cement                0\nBlast Furnace Slag    0\nFly Ash               0\nWater                 0\nSuperplasticizer      0\nCoarse Aggregate      0\nFine Aggregate        0\nAge                   0\nStrength              0\ndtype: int64"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "(1030, 9)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "predictors = data.drop(['Strength'], axis = 1 )\n",
    "targets = data['Strength']\n",
    "predictors = StandardScaler().fit_transform(X = predictors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(predictors, targets, random_state=365, test_size=0.2 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "931    15.34\n543    10.22\n996    26.86\n408    20.73\n276    29.65\n       ...  \n261    37.40\n428    24.66\n859    15.09\n801    19.69\n692    39.70\nName: Strength, Length: 824, dtype: float64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "nn_model = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "nn_model.add(Dense(100, activation='relu', input_shape=(8,)))\n",
    "nn_model.add(Dense(100, activation='relu'))\n",
    "nn_model.add(Dense(100, activation='relu'))\n",
    "nn_model.add(Dense(100, activation='relu'))\n",
    "nn_model.add(Dense(100, activation='relu'))\n",
    "nn_model.add(Dense(1))\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['Accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 - 1s - loss: 563.3018 - Accuracy: 0.0000e+00 - val_loss: 177.5090 - val_Accuracy: 0.0000e+00 - 1s/epoch - 56ms/step\n",
      "Epoch 2/150\n",
      "18/18 - 0s - loss: 84.7920 - Accuracy: 0.0000e+00 - val_loss: 54.9699 - val_Accuracy: 0.0000e+00 - 115ms/epoch - 6ms/step\n",
      "Epoch 3/150\n",
      "18/18 - 0s - loss: 26.6189 - Accuracy: 0.0000e+00 - val_loss: 33.6660 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 4/150\n",
      "18/18 - 0s - loss: 14.9714 - Accuracy: 0.0000e+00 - val_loss: 28.0910 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 5/150\n",
      "18/18 - 0s - loss: 9.9910 - Accuracy: 0.0000e+00 - val_loss: 26.9789 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 6/150\n",
      "18/18 - 0s - loss: 8.3117 - Accuracy: 0.0000e+00 - val_loss: 28.6928 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 7/150\n",
      "18/18 - 0s - loss: 7.6216 - Accuracy: 0.0000e+00 - val_loss: 27.1819 - val_Accuracy: 0.0000e+00 - 113ms/epoch - 6ms/step\n",
      "Epoch 8/150\n",
      "18/18 - 0s - loss: 6.8269 - Accuracy: 0.0000e+00 - val_loss: 27.0813 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 9/150\n",
      "18/18 - 0s - loss: 6.6355 - Accuracy: 0.0000e+00 - val_loss: 28.3965 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 10/150\n",
      "18/18 - 0s - loss: 6.3568 - Accuracy: 0.0000e+00 - val_loss: 27.8711 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 11/150\n",
      "18/18 - 0s - loss: 6.0338 - Accuracy: 0.0000e+00 - val_loss: 27.5649 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 12/150\n",
      "18/18 - 0s - loss: 5.8562 - Accuracy: 0.0000e+00 - val_loss: 27.2050 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 6ms/step\n",
      "Epoch 13/150\n",
      "18/18 - 0s - loss: 5.4434 - Accuracy: 0.0000e+00 - val_loss: 28.0403 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 14/150\n",
      "18/18 - 0s - loss: 6.4038 - Accuracy: 0.0000e+00 - val_loss: 28.9835 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 15/150\n",
      "18/18 - 0s - loss: 6.3420 - Accuracy: 0.0000e+00 - val_loss: 29.6358 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 16/150\n",
      "18/18 - 0s - loss: 5.4978 - Accuracy: 0.0000e+00 - val_loss: 28.8052 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 17/150\n",
      "18/18 - 0s - loss: 5.7868 - Accuracy: 0.0000e+00 - val_loss: 30.0725 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 18/150\n",
      "18/18 - 0s - loss: 5.4124 - Accuracy: 0.0000e+00 - val_loss: 28.5815 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 19/150\n",
      "18/18 - 0s - loss: 5.7438 - Accuracy: 0.0000e+00 - val_loss: 27.2223 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 20/150\n",
      "18/18 - 0s - loss: 5.5024 - Accuracy: 0.0000e+00 - val_loss: 28.2040 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 21/150\n",
      "18/18 - 0s - loss: 5.2815 - Accuracy: 0.0000e+00 - val_loss: 26.7482 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 22/150\n",
      "18/18 - 0s - loss: 4.9927 - Accuracy: 0.0000e+00 - val_loss: 27.2200 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 23/150\n",
      "18/18 - 0s - loss: 5.3453 - Accuracy: 0.0000e+00 - val_loss: 26.5929 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 24/150\n",
      "18/18 - 0s - loss: 5.6529 - Accuracy: 0.0000e+00 - val_loss: 28.6608 - val_Accuracy: 0.0000e+00 - 109ms/epoch - 6ms/step\n",
      "Epoch 25/150\n",
      "18/18 - 0s - loss: 5.7736 - Accuracy: 0.0000e+00 - val_loss: 26.6316 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 26/150\n",
      "18/18 - 0s - loss: 5.1128 - Accuracy: 0.0000e+00 - val_loss: 28.6715 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 27/150\n",
      "18/18 - 0s - loss: 5.4062 - Accuracy: 0.0000e+00 - val_loss: 30.8743 - val_Accuracy: 0.0000e+00 - 114ms/epoch - 6ms/step\n",
      "Epoch 28/150\n",
      "18/18 - 0s - loss: 6.6119 - Accuracy: 0.0000e+00 - val_loss: 28.9766 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 29/150\n",
      "18/18 - 0s - loss: 6.1390 - Accuracy: 0.0000e+00 - val_loss: 30.2751 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 30/150\n",
      "18/18 - 0s - loss: 5.3577 - Accuracy: 0.0000e+00 - val_loss: 26.6818 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 31/150\n",
      "18/18 - 0s - loss: 5.1147 - Accuracy: 0.0000e+00 - val_loss: 27.6548 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 32/150\n",
      "18/18 - 0s - loss: 5.3432 - Accuracy: 0.0000e+00 - val_loss: 30.8428 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 33/150\n",
      "18/18 - 0s - loss: 7.3825 - Accuracy: 0.0000e+00 - val_loss: 27.5332 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 34/150\n",
      "18/18 - 0s - loss: 6.5005 - Accuracy: 0.0000e+00 - val_loss: 27.6339 - val_Accuracy: 0.0000e+00 - 130ms/epoch - 7ms/step\n",
      "Epoch 35/150\n",
      "18/18 - 0s - loss: 7.1740 - Accuracy: 0.0000e+00 - val_loss: 29.4161 - val_Accuracy: 0.0000e+00 - 107ms/epoch - 6ms/step\n",
      "Epoch 36/150\n",
      "18/18 - 0s - loss: 6.3605 - Accuracy: 0.0000e+00 - val_loss: 31.4545 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 37/150\n",
      "18/18 - 0s - loss: 6.4728 - Accuracy: 0.0000e+00 - val_loss: 29.5396 - val_Accuracy: 0.0000e+00 - 101ms/epoch - 6ms/step\n",
      "Epoch 38/150\n",
      "18/18 - 0s - loss: 6.6404 - Accuracy: 0.0000e+00 - val_loss: 28.7938 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 39/150\n",
      "18/18 - 0s - loss: 5.8827 - Accuracy: 0.0000e+00 - val_loss: 31.0384 - val_Accuracy: 0.0000e+00 - 107ms/epoch - 6ms/step\n",
      "Epoch 40/150\n",
      "18/18 - 0s - loss: 5.1108 - Accuracy: 0.0000e+00 - val_loss: 28.1140 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 41/150\n",
      "18/18 - 0s - loss: 5.7255 - Accuracy: 0.0000e+00 - val_loss: 31.5072 - val_Accuracy: 0.0000e+00 - 112ms/epoch - 6ms/step\n",
      "Epoch 42/150\n",
      "18/18 - 0s - loss: 5.1516 - Accuracy: 0.0000e+00 - val_loss: 27.4703 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 43/150\n",
      "18/18 - 0s - loss: 5.3084 - Accuracy: 0.0000e+00 - val_loss: 26.6256 - val_Accuracy: 0.0000e+00 - 98ms/epoch - 5ms/step\n",
      "Epoch 44/150\n",
      "18/18 - 0s - loss: 6.0439 - Accuracy: 0.0000e+00 - val_loss: 31.0374 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 45/150\n",
      "18/18 - 0s - loss: 5.2584 - Accuracy: 0.0000e+00 - val_loss: 28.7295 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 46/150\n",
      "18/18 - 0s - loss: 5.5779 - Accuracy: 0.0000e+00 - val_loss: 29.1541 - val_Accuracy: 0.0000e+00 - 111ms/epoch - 6ms/step\n",
      "Epoch 47/150\n",
      "18/18 - 0s - loss: 5.5319 - Accuracy: 0.0000e+00 - val_loss: 32.4930 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 48/150\n",
      "18/18 - 0s - loss: 7.1468 - Accuracy: 0.0000e+00 - val_loss: 26.6529 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 49/150\n",
      "18/18 - 0s - loss: 5.4889 - Accuracy: 0.0000e+00 - val_loss: 27.9934 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 50/150\n",
      "18/18 - 0s - loss: 5.4429 - Accuracy: 0.0000e+00 - val_loss: 27.4137 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 51/150\n",
      "18/18 - 0s - loss: 4.9947 - Accuracy: 0.0000e+00 - val_loss: 28.5249 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 52/150\n",
      "18/18 - 0s - loss: 4.5831 - Accuracy: 0.0000e+00 - val_loss: 28.2375 - val_Accuracy: 0.0000e+00 - 107ms/epoch - 6ms/step\n",
      "Epoch 53/150\n",
      "18/18 - 0s - loss: 4.9800 - Accuracy: 0.0000e+00 - val_loss: 27.2971 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 54/150\n",
      "18/18 - 0s - loss: 5.2198 - Accuracy: 0.0000e+00 - val_loss: 30.3915 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 55/150\n",
      "18/18 - 0s - loss: 5.7548 - Accuracy: 0.0000e+00 - val_loss: 30.2201 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 56/150\n",
      "18/18 - 0s - loss: 7.2907 - Accuracy: 0.0000e+00 - val_loss: 31.9148 - val_Accuracy: 0.0000e+00 - 112ms/epoch - 6ms/step\n",
      "Epoch 57/150\n",
      "18/18 - 0s - loss: 6.1762 - Accuracy: 0.0000e+00 - val_loss: 29.9546 - val_Accuracy: 0.0000e+00 - 92ms/epoch - 5ms/step\n",
      "Epoch 58/150\n",
      "18/18 - 0s - loss: 6.6821 - Accuracy: 0.0000e+00 - val_loss: 30.2444 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 59/150\n",
      "18/18 - 0s - loss: 6.8200 - Accuracy: 0.0000e+00 - val_loss: 27.4843 - val_Accuracy: 0.0000e+00 - 116ms/epoch - 6ms/step\n",
      "Epoch 60/150\n",
      "18/18 - 0s - loss: 6.7979 - Accuracy: 0.0000e+00 - val_loss: 30.4203 - val_Accuracy: 0.0000e+00 - 112ms/epoch - 6ms/step\n",
      "Epoch 61/150\n",
      "18/18 - 0s - loss: 6.5305 - Accuracy: 0.0000e+00 - val_loss: 31.8047 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 62/150\n",
      "18/18 - 0s - loss: 6.6823 - Accuracy: 0.0000e+00 - val_loss: 28.7902 - val_Accuracy: 0.0000e+00 - 92ms/epoch - 5ms/step\n",
      "Epoch 63/150\n",
      "18/18 - 0s - loss: 7.3650 - Accuracy: 0.0000e+00 - val_loss: 27.9628 - val_Accuracy: 0.0000e+00 - 96ms/epoch - 5ms/step\n",
      "Epoch 64/150\n",
      "18/18 - 0s - loss: 7.8230 - Accuracy: 0.0000e+00 - val_loss: 28.0715 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 65/150\n",
      "18/18 - 0s - loss: 10.6509 - Accuracy: 0.0000e+00 - val_loss: 34.8008 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 5ms/step\n",
      "Epoch 66/150\n",
      "18/18 - 0s - loss: 9.3343 - Accuracy: 0.0000e+00 - val_loss: 32.3684 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 67/150\n",
      "18/18 - 0s - loss: 10.2822 - Accuracy: 0.0000e+00 - val_loss: 36.6913 - val_Accuracy: 0.0000e+00 - 111ms/epoch - 6ms/step\n",
      "Epoch 68/150\n",
      "18/18 - 0s - loss: 10.9068 - Accuracy: 0.0000e+00 - val_loss: 34.5032 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 69/150\n",
      "18/18 - 0s - loss: 6.1081 - Accuracy: 0.0000e+00 - val_loss: 28.6655 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 70/150\n",
      "18/18 - 0s - loss: 6.5340 - Accuracy: 0.0000e+00 - val_loss: 26.9669 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 71/150\n",
      "18/18 - 0s - loss: 9.7362 - Accuracy: 0.0000e+00 - val_loss: 27.9204 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 6ms/step\n",
      "Epoch 72/150\n",
      "18/18 - 0s - loss: 8.2558 - Accuracy: 0.0000e+00 - val_loss: 31.9197 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 73/150\n",
      "18/18 - 0s - loss: 5.8149 - Accuracy: 0.0000e+00 - val_loss: 29.8472 - val_Accuracy: 0.0000e+00 - 101ms/epoch - 6ms/step\n",
      "Epoch 74/150\n",
      "18/18 - 0s - loss: 4.9236 - Accuracy: 0.0000e+00 - val_loss: 29.6236 - val_Accuracy: 0.0000e+00 - 93ms/epoch - 5ms/step\n",
      "Epoch 75/150\n",
      "18/18 - 0s - loss: 9.2784 - Accuracy: 0.0000e+00 - val_loss: 30.6124 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 76/150\n",
      "18/18 - 0s - loss: 8.2628 - Accuracy: 0.0000e+00 - val_loss: 26.6212 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 77/150\n",
      "18/18 - 0s - loss: 5.1981 - Accuracy: 0.0000e+00 - val_loss: 27.5684 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 78/150\n",
      "18/18 - 0s - loss: 4.8975 - Accuracy: 0.0000e+00 - val_loss: 27.7666 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 79/150\n",
      "18/18 - 0s - loss: 5.2494 - Accuracy: 0.0000e+00 - val_loss: 28.9182 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 80/150\n",
      "18/18 - 0s - loss: 4.8820 - Accuracy: 0.0000e+00 - val_loss: 28.1257 - val_Accuracy: 0.0000e+00 - 108ms/epoch - 6ms/step\n",
      "Epoch 81/150\n",
      "18/18 - 0s - loss: 4.4158 - Accuracy: 0.0000e+00 - val_loss: 29.5166 - val_Accuracy: 0.0000e+00 - 117ms/epoch - 7ms/step\n",
      "Epoch 82/150\n",
      "18/18 - 0s - loss: 6.7733 - Accuracy: 0.0000e+00 - val_loss: 26.2296 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 83/150\n",
      "18/18 - 0s - loss: 6.0766 - Accuracy: 0.0000e+00 - val_loss: 27.2397 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 84/150\n",
      "18/18 - 0s - loss: 5.9002 - Accuracy: 0.0000e+00 - val_loss: 28.7137 - val_Accuracy: 0.0000e+00 - 107ms/epoch - 6ms/step\n",
      "Epoch 85/150\n",
      "18/18 - 0s - loss: 5.2699 - Accuracy: 0.0000e+00 - val_loss: 29.5528 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 86/150\n",
      "18/18 - 0s - loss: 5.2603 - Accuracy: 0.0000e+00 - val_loss: 27.9759 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 87/150\n",
      "18/18 - 0s - loss: 5.1626 - Accuracy: 0.0000e+00 - val_loss: 29.9922 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 5ms/step\n",
      "Epoch 88/150\n",
      "18/18 - 0s - loss: 5.2084 - Accuracy: 0.0000e+00 - val_loss: 30.1448 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 89/150\n",
      "18/18 - 0s - loss: 4.9972 - Accuracy: 0.0000e+00 - val_loss: 30.4495 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 6ms/step\n",
      "Epoch 90/150\n",
      "18/18 - 0s - loss: 4.2625 - Accuracy: 0.0000e+00 - val_loss: 29.7464 - val_Accuracy: 0.0000e+00 - 98ms/epoch - 5ms/step\n",
      "Epoch 91/150\n",
      "18/18 - 0s - loss: 4.5366 - Accuracy: 0.0000e+00 - val_loss: 27.9443 - val_Accuracy: 0.0000e+00 - 98ms/epoch - 5ms/step\n",
      "Epoch 92/150\n",
      "18/18 - 0s - loss: 6.1311 - Accuracy: 0.0000e+00 - val_loss: 27.3708 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 6ms/step\n",
      "Epoch 93/150\n",
      "18/18 - 0s - loss: 5.6337 - Accuracy: 0.0000e+00 - val_loss: 29.2320 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 94/150\n",
      "18/18 - 0s - loss: 4.4737 - Accuracy: 0.0000e+00 - val_loss: 27.0913 - val_Accuracy: 0.0000e+00 - 96ms/epoch - 5ms/step\n",
      "Epoch 95/150\n",
      "18/18 - 0s - loss: 4.5106 - Accuracy: 0.0000e+00 - val_loss: 34.4751 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 96/150\n",
      "18/18 - 0s - loss: 8.0186 - Accuracy: 0.0000e+00 - val_loss: 34.9748 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 97/150\n",
      "18/18 - 0s - loss: 7.1939 - Accuracy: 0.0000e+00 - val_loss: 29.3848 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 98/150\n",
      "18/18 - 0s - loss: 6.0802 - Accuracy: 0.0000e+00 - val_loss: 30.4517 - val_Accuracy: 0.0000e+00 - 98ms/epoch - 5ms/step\n",
      "Epoch 99/150\n",
      "18/18 - 0s - loss: 6.2636 - Accuracy: 0.0000e+00 - val_loss: 30.0377 - val_Accuracy: 0.0000e+00 - 93ms/epoch - 5ms/step\n",
      "Epoch 100/150\n",
      "18/18 - 0s - loss: 5.9822 - Accuracy: 0.0000e+00 - val_loss: 28.4219 - val_Accuracy: 0.0000e+00 - 92ms/epoch - 5ms/step\n",
      "Epoch 101/150\n",
      "18/18 - 0s - loss: 6.1330 - Accuracy: 0.0000e+00 - val_loss: 28.1259 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 102/150\n",
      "18/18 - 0s - loss: 6.2441 - Accuracy: 0.0000e+00 - val_loss: 30.0378 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 103/150\n",
      "18/18 - 0s - loss: 5.4530 - Accuracy: 0.0000e+00 - val_loss: 27.3435 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 104/150\n",
      "18/18 - 0s - loss: 5.5964 - Accuracy: 0.0000e+00 - val_loss: 30.6455 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 105/150\n",
      "18/18 - 0s - loss: 7.7364 - Accuracy: 0.0000e+00 - val_loss: 29.9359 - val_Accuracy: 0.0000e+00 - 96ms/epoch - 5ms/step\n",
      "Epoch 106/150\n",
      "18/18 - 0s - loss: 5.8899 - Accuracy: 0.0000e+00 - val_loss: 30.8295 - val_Accuracy: 0.0000e+00 - 101ms/epoch - 6ms/step\n",
      "Epoch 107/150\n",
      "18/18 - 0s - loss: 6.1720 - Accuracy: 0.0000e+00 - val_loss: 27.8015 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 108/150\n",
      "18/18 - 0s - loss: 5.3052 - Accuracy: 0.0000e+00 - val_loss: 29.7736 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 109/150\n",
      "18/18 - 0s - loss: 6.6903 - Accuracy: 0.0000e+00 - val_loss: 28.5385 - val_Accuracy: 0.0000e+00 - 111ms/epoch - 6ms/step\n",
      "Epoch 110/150\n",
      "18/18 - 0s - loss: 7.1135 - Accuracy: 0.0000e+00 - val_loss: 32.5701 - val_Accuracy: 0.0000e+00 - 98ms/epoch - 5ms/step\n",
      "Epoch 111/150\n",
      "18/18 - 0s - loss: 6.0873 - Accuracy: 0.0000e+00 - val_loss: 26.2675 - val_Accuracy: 0.0000e+00 - 98ms/epoch - 5ms/step\n",
      "Epoch 112/150\n",
      "18/18 - 0s - loss: 5.0925 - Accuracy: 0.0000e+00 - val_loss: 27.5803 - val_Accuracy: 0.0000e+00 - 107ms/epoch - 6ms/step\n",
      "Epoch 113/150\n",
      "18/18 - 0s - loss: 5.4577 - Accuracy: 0.0000e+00 - val_loss: 29.7681 - val_Accuracy: 0.0000e+00 - 97ms/epoch - 5ms/step\n",
      "Epoch 114/150\n",
      "18/18 - 0s - loss: 4.4348 - Accuracy: 0.0000e+00 - val_loss: 27.4227 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 6ms/step\n",
      "Epoch 115/150\n",
      "18/18 - 0s - loss: 4.8957 - Accuracy: 0.0000e+00 - val_loss: 29.6484 - val_Accuracy: 0.0000e+00 - 101ms/epoch - 6ms/step\n",
      "Epoch 116/150\n",
      "18/18 - 0s - loss: 4.8638 - Accuracy: 0.0000e+00 - val_loss: 28.4453 - val_Accuracy: 0.0000e+00 - 95ms/epoch - 5ms/step\n",
      "Epoch 117/150\n",
      "18/18 - 0s - loss: 4.8554 - Accuracy: 0.0000e+00 - val_loss: 28.8586 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 118/150\n",
      "18/18 - 0s - loss: 4.0369 - Accuracy: 0.0000e+00 - val_loss: 26.7763 - val_Accuracy: 0.0000e+00 - 96ms/epoch - 5ms/step\n",
      "Epoch 119/150\n",
      "18/18 - 0s - loss: 4.3485 - Accuracy: 0.0000e+00 - val_loss: 29.2815 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 120/150\n",
      "18/18 - 0s - loss: 4.3915 - Accuracy: 0.0000e+00 - val_loss: 28.8351 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 121/150\n",
      "18/18 - 0s - loss: 4.6024 - Accuracy: 0.0000e+00 - val_loss: 32.5517 - val_Accuracy: 0.0000e+00 - 94ms/epoch - 5ms/step\n",
      "Epoch 122/150\n",
      "18/18 - 0s - loss: 5.3819 - Accuracy: 0.0000e+00 - val_loss: 26.5041 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 5ms/step\n",
      "Epoch 123/150\n",
      "18/18 - 0s - loss: 4.5496 - Accuracy: 0.0000e+00 - val_loss: 26.4627 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 124/150\n",
      "18/18 - 0s - loss: 4.2318 - Accuracy: 0.0000e+00 - val_loss: 28.8130 - val_Accuracy: 0.0000e+00 - 113ms/epoch - 6ms/step\n",
      "Epoch 125/150\n",
      "18/18 - 0s - loss: 4.8129 - Accuracy: 0.0000e+00 - val_loss: 28.2323 - val_Accuracy: 0.0000e+00 - 105ms/epoch - 6ms/step\n",
      "Epoch 126/150\n",
      "18/18 - 0s - loss: 5.3175 - Accuracy: 0.0000e+00 - val_loss: 28.2851 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 127/150\n",
      "18/18 - 0s - loss: 4.5500 - Accuracy: 0.0000e+00 - val_loss: 27.4176 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 128/150\n",
      "18/18 - 0s - loss: 5.7357 - Accuracy: 0.0000e+00 - val_loss: 27.3652 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 129/150\n",
      "18/18 - 0s - loss: 5.5642 - Accuracy: 0.0000e+00 - val_loss: 28.8948 - val_Accuracy: 0.0000e+00 - 107ms/epoch - 6ms/step\n",
      "Epoch 130/150\n",
      "18/18 - 0s - loss: 3.8811 - Accuracy: 0.0000e+00 - val_loss: 28.0012 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 131/150\n",
      "18/18 - 0s - loss: 4.2878 - Accuracy: 0.0000e+00 - val_loss: 29.2788 - val_Accuracy: 0.0000e+00 - 100ms/epoch - 6ms/step\n",
      "Epoch 132/150\n",
      "18/18 - 0s - loss: 5.0047 - Accuracy: 0.0000e+00 - val_loss: 27.2410 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 133/150\n",
      "18/18 - 0s - loss: 4.7578 - Accuracy: 0.0000e+00 - val_loss: 28.4927 - val_Accuracy: 0.0000e+00 - 101ms/epoch - 6ms/step\n",
      "Epoch 134/150\n",
      "18/18 - 0s - loss: 5.5492 - Accuracy: 0.0000e+00 - val_loss: 25.9561 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 135/150\n",
      "18/18 - 0s - loss: 5.3826 - Accuracy: 0.0000e+00 - val_loss: 26.1043 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 6ms/step\n",
      "Epoch 136/150\n",
      "18/18 - 0s - loss: 7.4458 - Accuracy: 0.0000e+00 - val_loss: 27.1231 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 137/150\n",
      "18/18 - 0s - loss: 4.4517 - Accuracy: 0.0000e+00 - val_loss: 27.2153 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 138/150\n",
      "18/18 - 0s - loss: 4.5793 - Accuracy: 0.0000e+00 - val_loss: 28.1916 - val_Accuracy: 0.0000e+00 - 106ms/epoch - 6ms/step\n",
      "Epoch 139/150\n",
      "18/18 - 0s - loss: 4.5192 - Accuracy: 0.0000e+00 - val_loss: 30.2926 - val_Accuracy: 0.0000e+00 - 103ms/epoch - 6ms/step\n",
      "Epoch 140/150\n",
      "18/18 - 0s - loss: 5.9849 - Accuracy: 0.0000e+00 - val_loss: 28.7003 - val_Accuracy: 0.0000e+00 - 102ms/epoch - 6ms/step\n",
      "Epoch 141/150\n",
      "18/18 - 0s - loss: 4.6198 - Accuracy: 0.0000e+00 - val_loss: 28.9532 - val_Accuracy: 0.0000e+00 - 112ms/epoch - 6ms/step\n",
      "Epoch 142/150\n",
      "18/18 - 0s - loss: 4.4933 - Accuracy: 0.0000e+00 - val_loss: 27.3383 - val_Accuracy: 0.0000e+00 - 110ms/epoch - 6ms/step\n",
      "Epoch 143/150\n",
      "18/18 - 0s - loss: 4.5743 - Accuracy: 0.0000e+00 - val_loss: 27.0149 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 144/150\n",
      "18/18 - 0s - loss: 4.0343 - Accuracy: 0.0000e+00 - val_loss: 27.2420 - val_Accuracy: 0.0000e+00 - 99ms/epoch - 5ms/step\n",
      "Epoch 145/150\n",
      "18/18 - 0s - loss: 4.2370 - Accuracy: 0.0000e+00 - val_loss: 27.9540 - val_Accuracy: 0.0000e+00 - 96ms/epoch - 5ms/step\n",
      "Epoch 146/150\n",
      "18/18 - 0s - loss: 4.6674 - Accuracy: 0.0000e+00 - val_loss: 27.2123 - val_Accuracy: 0.0000e+00 - 96ms/epoch - 5ms/step\n",
      "Epoch 147/150\n",
      "18/18 - 0s - loss: 5.5496 - Accuracy: 0.0000e+00 - val_loss: 31.7343 - val_Accuracy: 0.0000e+00 - 104ms/epoch - 6ms/step\n",
      "Epoch 148/150\n",
      "18/18 - 0s - loss: 5.0026 - Accuracy: 0.0000e+00 - val_loss: 29.4922 - val_Accuracy: 0.0000e+00 - 165ms/epoch - 9ms/step\n",
      "Epoch 149/150\n",
      "18/18 - 0s - loss: 6.3429 - Accuracy: 0.0000e+00 - val_loss: 28.5828 - val_Accuracy: 0.0000e+00 - 142ms/epoch - 8ms/step\n",
      "Epoch 150/150\n",
      "18/18 - 0s - loss: 4.5352 - Accuracy: 0.0000e+00 - val_loss: 27.7977 - val_Accuracy: 0.0000e+00 - 164ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fa38a8bd400>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(x_train, y_train, epochs=150, verbose=2, validation_split=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[13.021096 ],\n       [26.658266 ],\n       [36.025944 ],\n       [11.797447 ],\n       [10.848517 ],\n       [22.470015 ],\n       [40.87208  ],\n       [23.142044 ],\n       [45.82244  ],\n       [ 9.838052 ],\n       [74.192444 ],\n       [29.992914 ],\n       [34.19732  ],\n       [10.6216   ],\n       [38.31181  ],\n       [14.423216 ],\n       [ 6.042584 ],\n       [30.582651 ],\n       [55.37068  ],\n       [20.79984  ],\n       [ 9.736181 ],\n       [21.077656 ],\n       [31.797674 ],\n       [52.91148  ],\n       [35.901894 ],\n       [28.243582 ],\n       [34.02901  ],\n       [35.105682 ],\n       [17.833076 ],\n       [79.7353   ],\n       [52.214848 ],\n       [50.745144 ],\n       [31.301231 ],\n       [27.960377 ],\n       [34.19066  ],\n       [35.347763 ],\n       [41.856922 ],\n       [46.904957 ],\n       [33.789417 ],\n       [13.083788 ],\n       [52.78616  ],\n       [45.486874 ],\n       [30.839455 ],\n       [61.2334   ],\n       [30.195196 ],\n       [19.210005 ],\n       [18.329916 ],\n       [16.035227 ],\n       [23.957361 ],\n       [29.029108 ],\n       [46.51248  ],\n       [41.420055 ],\n       [45.153645 ],\n       [28.735106 ],\n       [11.273296 ],\n       [31.07021  ],\n       [14.5078335],\n       [32.562958 ],\n       [15.985933 ],\n       [58.891277 ],\n       [48.41061  ],\n       [31.959837 ],\n       [46.28811  ],\n       [29.664503 ],\n       [35.236984 ],\n       [63.85439  ],\n       [38.882977 ],\n       [42.639206 ],\n       [67.34823  ],\n       [63.65475  ],\n       [44.186134 ],\n       [26.754522 ],\n       [14.167404 ],\n       [51.418804 ],\n       [17.434868 ],\n       [73.68948  ],\n       [27.237127 ],\n       [76.057594 ],\n       [72.41987  ],\n       [24.324217 ],\n       [11.551121 ],\n       [38.211807 ],\n       [17.8392   ],\n       [54.909775 ],\n       [22.908375 ],\n       [62.355022 ],\n       [22.189241 ],\n       [32.10965  ],\n       [48.806522 ],\n       [66.460236 ],\n       [13.313879 ],\n       [ 7.556472 ],\n       [47.21048  ],\n       [26.28281  ],\n       [63.376728 ],\n       [20.823256 ],\n       [57.382088 ],\n       [36.925575 ],\n       [52.30332  ],\n       [37.787388 ],\n       [11.362571 ],\n       [13.547848 ],\n       [26.130495 ],\n       [50.63825  ],\n       [29.667162 ],\n       [38.37253  ],\n       [69.30244  ],\n       [50.131878 ],\n       [24.180357 ],\n       [51.2204   ],\n       [35.83228  ],\n       [55.604134 ],\n       [14.973    ],\n       [34.440132 ],\n       [32.817867 ],\n       [41.829445 ],\n       [18.571995 ],\n       [24.758202 ],\n       [33.913036 ],\n       [43.34394  ],\n       [38.22802  ],\n       [19.122072 ],\n       [37.47505  ],\n       [10.226797 ],\n       [15.628115 ],\n       [25.72809  ],\n       [15.360758 ],\n       [26.213762 ],\n       [30.141535 ],\n       [20.917147 ],\n       [27.977524 ],\n       [30.724773 ],\n       [23.069435 ],\n       [33.67837  ],\n       [13.527535 ],\n       [25.367483 ],\n       [33.44049  ],\n       [27.47138  ],\n       [56.437233 ],\n       [27.136553 ],\n       [40.108517 ],\n       [65.76293  ],\n       [38.665215 ],\n       [59.725063 ],\n       [41.934776 ],\n       [64.03896  ],\n       [11.332962 ],\n       [47.369682 ],\n       [15.669689 ],\n       [47.557503 ],\n       [67.78344  ],\n       [41.618187 ],\n       [71.50141  ],\n       [28.83803  ],\n       [45.983894 ],\n       [44.66377  ],\n       [31.688114 ],\n       [ 9.575021 ],\n       [37.329155 ],\n       [18.335785 ],\n       [ 8.739452 ],\n       [49.905964 ],\n       [36.196617 ],\n       [63.104706 ],\n       [24.819313 ],\n       [80.25482  ],\n       [ 3.7908087],\n       [42.73951  ],\n       [15.247492 ],\n       [49.052933 ],\n       [28.700417 ],\n       [65.305664 ],\n       [31.47039  ],\n       [15.491515 ],\n       [ 9.524873 ],\n       [51.765972 ],\n       [53.295273 ],\n       [45.261463 ],\n       [11.091323 ],\n       [67.93351  ],\n       [17.536743 ],\n       [37.340538 ],\n       [35.338818 ],\n       [36.242367 ],\n       [42.164196 ],\n       [68.67548  ],\n       [34.315895 ],\n       [41.229504 ],\n       [30.938152 ],\n       [34.030594 ],\n       [21.614508 ],\n       [17.814798 ],\n       [56.69821  ],\n       [48.900616 ],\n       [31.817598 ],\n       [41.52205  ],\n       [48.06025  ],\n       [34.959003 ],\n       [31.529171 ],\n       [15.650788 ],\n       [32.668205 ],\n       [24.704395 ],\n       [32.613003 ],\n       [36.78237  ],\n       [42.578457 ],\n       [20.353762 ]], dtype=float32)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = nn_model.predict(x_test)\n",
    "yhat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9038320011726444"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, yhat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}